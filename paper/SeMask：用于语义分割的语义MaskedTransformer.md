## SeMask：用于语义分割的语义Masked Transformer

> （SeMask: Semantically Masked Transformers for Semantic Segmentation）个人理解：将语义地Masked Transformer信息用于语义分割。

### 摘要

在图像`transformer`网络的解码部分，对预训练主干结构进行微调一直是语义分割任务的传统方法。然而，**这种方法省略了图像在编码阶段提供的语义上下文信息。**本文论述，将语义信息整合到预训练分层级的`transformer-base`主干上，同时对其进行微调，可以显著提高信息。为了实现这个，我们提出了`SeMask`，一种简单有效的框架，借助于语义注意力操作，将语义信息整合到编码器中。另外，在训练中，我们使用了一个轻量级的语义解码器，在每个阶段对中间语义先验映射进行监督。我们的实验表明，语义先验的加入提高了所建立的层次编码器的性能，增加了少量`FLOPs`。我们通过将`SeMask`集成到每个变体的`Swin-Transformer`中，作为与不同解码器配对的编码器，提供了经验证明。我们的框架在`ADE20K`数据集上达到了`58.22% mIoU`的最新技术水平和在`Cityscapes`数据集上`mIoU`指标的改进超过`3%`。代码和模型公开在：[https://github.com/PicsartAI-Research/SeMask-Segmentation](t https://github.com/PicsartAI-Research/SeMask-Segmentation)。

### 1.介绍

语义分割旨在执行密集预测，以标记图像中的每个像素，该像素对应于改像素所代表的类。基于`transformer`的视觉网络在图像分类任务中的表现优于卷积神经网络。在现代，当转移到语义分割等下游任务时，`transformer`骨干已经显示出令人印象深刻的性能。

视觉'transformer'中的大多数框架设计都以两种方式之一来解决问题：(1)使用现有的预先训练的主干作为编码器，并使用现有的标准解码器(如`Semantic FPN`或`UperNet`)将其传输到下游任务；或者(2)设计一种新的编码器-解码器网络，在`ImageNet`上对编码器进行预处理，完成语义分割任务。正如前面提到的，这两种方法都涉及到对分割任务的编码器骨干进行微调。从大规模数据集进行微调，有助于早期的注意层在`transformer`的较低层合并局部信息。然而，由于数据集相对较小，并且从分类任务到分割任务，语义类的数量和性质发生了变化，因此在精细调优过程中仍然不能利用语义上下文信息。分层视觉`transformer`解决了沿着阶段逐级下下采样特征的问题，尽管它们仍然缺乏图像的语义上下文。

`Liu`等人介绍了`Swin Transformer`，它构建了分层特征图，使其与主要下游视觉任务的通用骨干兼容。建议使用两个注意力：全局下采样和局部下采样在`PVT`和`CPVT`有效分割。`Xie`等人进一步改进了分层`transformer`编码器，使其不受位置编码的影响，从而对分割任务中通常发现的不同分辨率具有鲁棒性。所有这些工作都对编码器进行了改进，使其更好地工作于下游任务，如分割，并取得了令人印象深刻的成功。然而，他们并没有注意捕捉整个图像的语义级上下文信息。缺乏语义级上下文信息会导致次优的分割性能，特别是在小对象的情况下，这些对象与较大类别的边界合并，导致错误的预测。最近，有人试图通过设计一个纯基于`transformer`的解码器来解决这个问题，该解码器将`patch`和类嵌入联合处理。然而，当与`Swin`和`Twins Transformers`等主要变压器骨干一起使用时，它对于微小的变体并不能有效地执行，并且由于分层架构导致次优性能而失败。

`Jin`等人，提出`ISNet`通过在解码器结构中引入`SLCM`和`ILCM`模块来对图像级上下文信息和语义级上下文信息进行建模。但是仍然有一点需要注意：`ISNet`是一种基于`CNN`的方法，只关注网络的解码器部分，而没有改变编码器。

![image-20220214230159992](.\SeMask：用于语义分割的语义MaskedTransformer\image-20220214230159992.png)

为解决上述问题，我们提出`SeMask`框架，将语义信息整合到层次视觉`transformer`体系结构中，并通过语义上下文增强`transformer`捕获的全局特征信息。现有框架将该体系结构描述为一个编码器-解码器结构，其中在`ImageNet`上预先训练的`transformer`充当编码器，并使用专门的解码器进行语义分割。与直接使用分层`transformer`作为主干相比，我们在主干的每个阶段的`transformer`层之后插入一个语义层，从而得到主干的`SeMask`版本，如图1所示。在图1中，我们展示了提供语义先验如何帮助改进最终的分割图。我们使用轻量级语义解码器来累积来自所有阶段的语义图，并使用像`Semantic-FPN`这样的标准解码器来进行主要的逐像素预测。**在整个编码器中添加语义建模和特征建模，有助于提高语义分割任务的性能。**在第4节中，我们将提出的`SeMask`块`Semantic-FPN`和`MaskFormer`解码器集成到`Swin Transformer`中，并使用四种不同的`transformer`变体进行实验：`Tiny、Small、Base和Large`。我们的实验结果表明，在两个不同的数据集上，所有的变形在语义分割上有相当大的改进。总之，我们的贡献有三点：

- 据我们所知，我们是第一个研究添加语义上下文到预先训练的`transformer`主干中用于语义分割的效果。此外，我们引入了`SeMask Block`模块，该模块可以插入任何现有的分层视觉`transformer`。
- 我们也建议使用一个简单的语义解码器来聚合来自编码器不同阶段的语义先验。使用每像素交叉熵损失的`ground true`分割标签对语义先验进行监督。
- 最后，我们深入的分析`SeMask Block`对不同数据集`ADE20k和Cityscenes`的影响。我们在`ADE20k`数据集上实现了新的最先进的性能，并在`Cityscenes`数据集上使用`SeMask Swin-Tiny+FPN`框架实现了3%以上的改进。

### 2.相关工作

#### 2.1.语义分割

语义分割广义上形成了密集的逐像素分类任务。`FCN`的开创性工作介绍了深度`CNN` 的使用，去除完全连接的层来处理分割任务。接下来的几部作品都基于同样的思想，即使用编码器-解码器结构。引入了在`DCNN`中使用`astrous`卷积来解决信号下采样问题。后来，各方面的工作都集中在最终的`feature map`中聚合的远程上下文上：`ASPP`使用不同膨胀率的空洞卷积；`PPM`使用不同内核大小的池化算子。

最近基于`DCNN`的模型专注于有效地聚合来自预训练的基于主干的编码器的分层特征，并带有专门设计的模块：在解码器中引入注意模块；使用不同形式的非局部模块；提出了一种新颖的`FAM`模块来解决使用语义流的错位问题；`AlignSeg`提出了对齐特征聚合模块和对齐上下文建模模块，以使上下文特征更好地对齐。使用分割架来获得更好的信息流。在这项工作中，我们还按照既定方向使用预训练的主干，并使用`Semantic-FPN`解码器聚合分层特征。

#### 2.2.使用`Transformer`的分割

在自然语言处理领域被大量使用后，基于`transformer`的模型自从引入`ViT`用于图像分类以来，已经在各种计算机视觉任务中广受欢迎。`SETR`使用`ViT`作为编码器和两个基于渐进上采样和多级特征聚合的解码器。`SegFormer`提出使用分层金字塔视觉`transformer`网络作为编码器和基于`MLP`的解码器来获得分割掩码。`Segmenter`将掩码转化器设计为解码器，它使用可学习的类映射标记来提高解码性能。`MaskFormer`从掩模分类的角度定义了每像素分类的问题，为所有分割任务创建了一个一体化模块。`Mask2Former`进一步发展了掩蔽注意力，以在一个框架中解决全景、实例和语义分割任务。最新的基于`transformer`的分割框架是基于微调预训练的分层主干作为解码器，以及像`Semantic-FPN`和`UperNet`这样的标准解码器来完成分割任务。在这项工作中，我们遵循相同的范式，此外，提出了一个框架来增强预训练的视觉`transformer`主干的微调能力。请注意，最近还有像`SwinV2`这样的并行工作，通过使用改进的巨型主干（例如具有30亿个参数的`SwinV2-G`），在`ADE20k`基准上达到了新的最先进性能。这超出了这项工作的范围，我们遵循主要基于`Swin-L`主干的当前实践。从理论上讲，如果我们将我们的方法应用于此类巨型模型，我们可以获得更好的性能。

#### 2.3.分割中的语义上下文

`zhang`等人，提出了上下文编码模块，它捕获全局语义上下文以及反馈循环，以平衡`ResNet`主干提取的特征中类的重要性。最近，专注于使用专门设计的解码器捕获和集成语义级上下文信息以及图像级上下文，这显示了基于`DCNN`的方法德 显著改进。这些作品中的每一个都基于提取的特征而不是编码器捕获语义特征的能力在编码器阶段之后捕获语义上下文。

在这项工作中，我们认为语义信息在编码阶段会丢失，因此，提出了一个框架来捕获语义信息，该框架可以插入任何预训练的视觉`transformer`骨干网络。

### 3.方法

![image-20220215092236102](.\SeMask：用于语义分割的语义MaskedTransformer.assets\image-20220215092236102.png)

我们的框架概述如图2所示，输入尺寸为$H\times W\times 3$的RGB图像，首先被分割成大小为$4\times 4$的不重叠的块(`patches`)。较小尺寸的块支持分割中的密集预测。这些块作为`tokens`，并作为分层视觉`transformer`编码器(即我们的体系结构中的`Swin-Transformer`)的输入。编码步骤包括四个不同的层次特征阶段。编码过程中的每个阶段由两层组成：`transformer`层，它是$N_A$个`Swin Transformer`块(`Fig.3a`)堆叠在一起，语义层带有$N_s$个`SeMask`注意力块(`Fig.3b`)。我们将每个阶段的`transformer`层和语义层统称为我们的`SeMask`块。块的`token`通过每个阶段以原始影像分辨率的${\frac{1}{4},\frac{1}{8},\frac{1}{16},\frac{1}{32}}$，对于特征图和中间语义先验图提取。

在网络的编码部分，语义层从`transformer`层获取特征作为输入，并返回中间语义先验图和语义掩码特征(`Fig.3b`)。使用语义`FPN`解码器对每个阶段的语义掩码特征进行聚合，生成最终的密集像素预测。并且所有

阶段的语义先验图都使用基于轻量级上采样和求和操作的语义解码器进行聚合，以在训练期间预测网络的语义先验。两个解码器的输出使用加权的每像素交叉熵损失进行监督。这些额外的语义先验图极大地帮助了特征提取并最终提高了语义分割任务的性能。

![image-20220216095217515](SeMask：用于语义分割的语义MaskedTransformer.assets\image-20220216095217515.png)

#### 3.1.`SeMask`编码器

编码器中的每个阶段由两层组成：`Transformer`层和语义层。`transformer`层由$N_A$个`Swin Transformer`块堆叠组成，同来从图像中提取图像级语义上下文信息。语义层包含$N_S$个`SeMask`注意块，将语义信息与特征解耦，产生语义先验，然后根据这些语义先验映射指导特征更新。

**Transformer层：**`Transformer`层采用`Swin transformer`的分层结构，构造分层特征映射，计算复杂度与图像分辨率成线性关系。在第一阶段将RGB图像送入变压器层之前，我们将其分割成大小不重叠的小块$4 × 4 × 3 = 48。$编码器的第一阶段有一个线性嵌入层，用于改变`patch`令牌的特征维数。在每个` Transformer `层内，有 $N_A$ 移位窗口注意块（Fig. 3a），具有线性计算复杂度以及处理非重叠区域的跨窗口连接，使设计对图像级特征建模有效。对于分层表示，我们通过块合并层将我们的特征图从 H 缩小到 W 以用于下一阶段。在接下来的阶段中，迭代这个patch的合并，以获得一个分层的特征图，其分辨率为。X表示变压器层块内部的输入特征。对于变压器层的自注意计算，将X变换为:Q、K、V是同维N × C的查询、键、值矩阵。基于swin变压器，我们还遵循[3,21,22,36,39]，包括RPE∈R的相对位置嵌入(RPE)N×N, N = M × M为窗口大小为M的序列的长度。Transformer 层内部的注意力计算如下：

$$aa$$

**语义层：**在我们的分层视觉转换器的每个阶段，语义层都遵循转换器层。 与 Transformer 层不同，语义层的意义在于对语义上下文进行建模，语义上下文用作计算分割分数的先验，以根据图像中存在的语义性质的指导更新特征图。在每个语义层，受基于移动窗口的令牌划分以提高计算成本的启发，我们还将 SeMask 块的输入划分为具有跨窗口连接的窗口，然后使用单头自注意力操作计算分割分数。 SeMask 块负责在我们的编码器中捕获语义上下文。 它根据分割分数更新转换器层的特征，提供指导并给出语义先验图，以便在训练期间有效监督语义建模。SeMask 注意力块将来自前面转换器层的特征 Y 分为三个实体：语义查询（SQ）、语义键（SK）和特征值（YV）。我们通过将特征投影到语义空间来获得 SK 和 SQ。SQ 和 SK 的维度都是 N × K，其中 K 等于类数，YV 的维度是 N × C，其中 C 是嵌入维度，N = M × M 是序列的长度，其中 M = 我们设置的窗口大小等于变压器层内部使用的窗口大小。SQ返回语义映射，使用SK和SQ计算分割分数。分数通过softmax并用于更新YV，如图3b所示。这个SeMask注意方程表示如下:

$$$$

我们在特征值和分割分数之间执行矩阵乘法。 矩阵乘积稍后通过线性层并乘以可学习的标量常数 λ，用于平滑微调。 在残差连接 [20] 之后，我们最终得到了修改后的特征，这些特征富含语义信息，我们称之为语义掩蔽特征。 语义查询 SQ 稍后用于预测语义先验图。

#### 解码器

我们使用两个解码器分别从编码器的不同阶段聚合特征和语义先验映射。

为了聚合语义屏蔽的特征，我们采用了流行的Semantic-FPN解码器。语义fpn通过一系列的卷积、双线性上采样和求和运算，融合了不同阶段的特征，使其成为一种高效、直接的分割解码器。此外，在训练过程中，我们使用了一个轻量级的语义解码器，在编码器的每个阶段对语义优先映射提供地面真相监督。由于语义优先映射在每个阶段的通道维数为K，因此我们只采用一系列上采样和求和操作对K等于数据集中类数的映射进行聚合。最后，两个解码器的输出都被放大×4到原始图像的分辨率最终预测如图2所示

